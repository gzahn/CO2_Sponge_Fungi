BiocManager::install("phyloseq")
install.packages("igraph")
install.packages("igraph")
install.packages("igraph")
BiocManager::install("phyloseq")
install.packages("vegan")
# dependencies = TRUE, INSTALL_opts = '--no-lock'
#
BiocManager::install("phyloseq",update = FALSE)
# PACKAGES, SCRIPTS, AND SETUP ####
library(tidyverse); packageVersion("tidyverse")
library(dada2); packageVersion("dada2")
library(decontam); packageVersion("decontam")
library(phyloseq); packageVersion("phyloseq")
# File parsing - For this, we will use only the forward illumina reads - make sure to move fwd reads into their own directory for simplest processing
path <- "./seqs/fastqs/" # CHANGE to the directory containing your demultiplexed fastq files
filtpath <- file.path(path, "filtered") # Filtered files go into the filtered/ subdirectory
if(!file_test("-d", filtpath)) dir.create(filtpath) # make directory for filtered fqs if not already present
fns <- sort(list.files(file.path(path), full.names = TRUE, pattern = "001.fastq.gz.FungalITS1.fastq.gz"))
fns
# File parsing - For this, we will use only the forward illumina reads - make sure to move fwd reads into their own directory for simplest processing
path <- "./seqs/fastqs" # CHANGE to the directory containing your demultiplexed fastq files
filtpath <- file.path(path, "filtered") # Filtered files go into the filtered/ subdirectory
if(!file_test("-d", filtpath)) dir.create(filtpath) # make directory for filtered fqs if not already present
fns <- sort(list.files(file.path(path), full.names = TRUE, pattern = "001.fastq.gz.FungalITS1.fastq.gz"))
fns
sample.names <- sapply(strsplit(basename(fns), ".fastq"), `[`, 1)
sample.names
fns <- sort(list.files(file.path(path), full.names = TRUE, pattern = "_R1_001.fastq.gz.FungalITS1.fastq.gz"))
fns
basename(fns)
strsplit(basename(fns), ".fastq")
strsplit(basename(fns), "\.")
strsplit(basename(fns), "\\.")
sapply(strsplit(basename(fns), "\\."), `[`, 3)
strsplit(basename(fns), "fastq")
sapply(strsplit(basename(fns), "\\."), `[`, 3)
sapply(strsplit(basename(fns), "\\."), `[`, 1:3)
library(purrr); packageVersion("purrr")
map(strsplit(basename(fns), "\\."), 1:3)
map(strsplit(basename(fns), "\\."), 1)
unlist(map(strsplit(basename(fns), "\\."), 1))
A <- unlist(map(strsplit(basename(fns), "\\."), 1))
A <- unlist(map(strsplit(basename(fns), "\\."), 1))
B <- unlist(map(strsplit(basename(fns), "\\."), 2))
C <- unlist(map(strsplit(basename(fns), "\\."), 3))
paste(A,B,C,sep = "_")
sample.names <- paste(A,B,C,sep = "_")
rm(list = c(A))
rm(list = c("A"))
rm(list = c("A","B","C"))
# visualize a couple of fwd read quality profiles to help select reasonable filtration parameters
plotQualityProfile(fns[3:4])
# visualize a couple of fwd read quality profiles to help select reasonable filtration parameters
plotQualityProfile(fns[1:4])
# FILTER AND TRIM ####
filts <- file.path(path, "filtered", paste0(sample.names, "_filt.fastq.gz"))
filts
out <- filterAndTrim(fns, filts, # fnRs, filtRs,
maxN=0, maxEE=c(2), truncQ=2, rm.phix=TRUE,
compress=TRUE, multithread=4) # On Windows set multithread=FALSE
# sanity check  comparison of before and after filtration
plotQualityProfile(c(fns[1:2],filts[1:2]))
# LEARN ERROR RATES ####
# Since some samples may have had zero reads pass QC, reassign filts
filts <- sort(list.files(filtpath, full.names = TRUE))
filts
errF <- learnErrors(filts, multithread=TRUE, MAX_CONSIST = 20)
# sanity check for error model
plotErrors(errF, nominalQ=TRUE)
# DEREPLICATION ####
derep <- derepFastq(filts, verbose=TRUE)
length(derep)
# Name the derep-class objects by the sample names
# If some samples were removed (no reads passed QC), reassign sample.names
if(length(derep) != length(sample.names)){
A <- unlist(map(strsplit(basename(fns), "\\."), 1))
B <- unlist(map(strsplit(basename(fns), "\\."), 2))
C <- unlist(map(strsplit(basename(fns), "\\."), 3))
sample.names <- paste(A,B,C,sep = "-")
rm(list = c("A","B","C"))
}
basename(filts)
strsplit(basename(filts), "filt")
strsplit(basename(filts), "_filt")
names(derep) <- sample.names
names(derep)
derep
?dada
# SAMPLE INFERRENCE ####
dadaFs <- dada(derep, err=errF, multithread=TRUE, selfConsist = TRUE, verbose=TRUE, pool = "pseudo")
# MAKE SEQUENCE TABLE ####
seqtab <- makeSequenceTable(dadaFs)
# REMOVE CHIMERAS ####
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
sum(seqtab.nochim)/sum(seqtab)
# reassign "out" to remove any missing reads
out = out[as.data.frame(out)$reads.out > 0,]
out
# TRACK READS THROUGH PIPELINE ####
getN <- function(x) sum(getUniques(x))
track <- cbind(out[,1], sapply(dadaFs, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "nonchim")
rownames(track) <- sample.names
track = as.data.frame(track)
track$filter.loss = (track[,1]-track[,2])/track[,1]
track
head(track)
track <- cbind(out[,1], sapply(dadaFs, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "nonchim")
rownames(track) <- sample.names
track = as.data.frame(track)
track$total.loss = (track[,1]-track[,2])/track[,1]
head(track)
# TRACK READS THROUGH PIPELINE ####
getN <- function(x) sum(getUniques(x))
track <- cbind(out[,1], sapply(dadaFs, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "nonchim")
rownames(track) <- sample.names
track = as.data.frame(track)
track$total.loss.proportion = (track[,1]-track[,2])/track[,1]
head(track)
write.csv(track, file = "./output/read_counts_at_each_step.csv", row.names = TRUE)
# Save intermediate seqtable object
saveRDS(seqtab.nochim, "./output/seqtab.nochim.RDS")
# PACKAGES, SCRIPTS, AND SETUP ####
library(tidyverse); packageVersion("tidyverse")
# IMPORT METADATA ####
meta = read_delim("./data/Metadata.txt", header = TRUE)
# IMPORT METADATA ####
meta = read_delim("./data/Metadata.txt")
# IMPORT METADATA ####
meta = read_delim("./data/Metadata.txt",delim = "\t")
meta
row.names(meta) <- as.character(meta$SampleID)
row.names(seqtab.nochim)
# IMPORT METADATA ####
meta = read_delim("./data/Metadata.csv",delim = ",")
meta
meta$Latitude
row.names(seqtab.nochim)
sample.names
# IMPORT METADATA ####
meta = read_delim("./data/Metadata.csv",delim = ",")
meta
row.names(meta) <- as.character(meta$SampleID)
row.names(seqtab.nochim)
row.names(meta)
identical(row.names(meta),row.names(seqtab.nochim))
meta
# are the "Seawater" samples negative controls????
meta$Description
nchar(names(as.data.frame(seqtab.nochim))) > 99
# Remove all seqs with fewer than 100 nucleotides ####
keeper_esvs <- nchar(names(as.data.frame(seqtab.nochim))) > 99
seqtab.nochim <- seqtab.nochim[,keeper_esvs]
# ASSIGN TAXONOMY ####
taxa <- assignTaxonomy(seqtab.nochim, "./taxonomy/UNITE_Euk_2020-02-04_non-dev.fasta.gz", multithread=4)
saveRDS(taxa, file = "./output/RDP_Taxonomy_from_dada2.RDS")
# Save intermediate files
write.csv(as.data.frame(seqtab.nochim), file = "./output/SeqTable_no-chimera.csv", row.names = TRUE, quote = FALSE)
saveRDS(seqtab.nochim, file = "./output/dada2_seqtable.RDS")
saveRDS(taxa, file = "./output/RDP_Taxonomy_from_dada2.RDS")
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE),
sample_data(meta),
tax_table(taxa))
sample_names(seqtab.nochim)
names(seqtab.nochim)
row.names(seqtab.nochim)
row.names(meta)
colnames(taxa)
names(taxa)
row.names(taxa)
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE),
sample_data(meta),
tax_table(taxa))
row.names(seqtab.nochim)
row.names(meta)
identical(row.names(seqtab.nochim),row.names(meta))
sample_names(meta)
sample_names(seqtab.nochim)
sample_names(seqtab.nochim) <- row.names(seqtab.nochim)
sample_names(meta) <- row.names(meta)
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE),
sample_data(meta),
tax_table(taxa))
sample_names(meta)
sample_names(meta) <- row.names(meta)
sample_names(meta)
identical(row.names(seqtab.nochim),row.names(meta))
otu <- otu_table(seqtab.nochim,taxa_are_rows = FALSE)
tax <- tax_table(taxa)
met <- sample_data(meta)
ps <- phyloseq(otu,met,tax)
dim(otu)
dim(meta)
dim(met)
dim(tax)
row.names(tax)
colnames(seqtab.nochim)
identical(row.names(tax),colnames(seqtab.nochim))
ps <- phyloseq(otu,met,tax)
row.names(met) <- row.names(meta)
ps <- phyloseq(otu,met,tax)
tax_table(ps)
tax_table(ps)[,1]
unique(tax_table(ps)[,1])
ps
# REMOVE NON-FUNGI ####
ps %>% subset_taxa(Kingdom == "k__Fungi")
# REMOVE NON-FUNGI ####
ps <- ps %>% subset_taxa(Kingdom == "k__Fungi")
subset_taxa(ps, taxa_sums(ps) > 0)
ps <- subset_taxa(ps, taxa_sums(ps) > 0)
subset_samples(ps, sample_sums(ps) > 0)
ps <- subset_samples(ps, sample_sums(ps) > 0)
# Save RDS object for Phyloseq
saveRDS(ps, file = "./output/clean_phyloseq_object.RDS")
packageVersion("vegan")
